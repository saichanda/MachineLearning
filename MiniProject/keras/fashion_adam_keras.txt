]0;IPython: MlProject/fashionmnist_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 13, 13, 32)        0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 11, 11, 64)        18496     
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 5, 5, 64)          0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 5, 5, 64)          0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 3, 3, 128)         73856     
_________________________________________________________________
dropout_3 (Dropout)          (None, 3, 3, 128)         0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 1152)              0         
_________________________________________________________________
dense_1 (Dense)              (None, 128)               147584    
_________________________________________________________________
dropout_4 (Dropout)          (None, 128)               0         
_________________________________________________________________
dense_2 (Dense)              (None, 10)                1290      
=================================================================
Total params: 241,546
Trainable params: 241,546
Non-trainable params: 0
_________________________________________________________________
Train on 42000 samples, validate on 18000 samples
Epoch 1/50
42000/42000 [==============================] - 26s 609us/step - loss: 2.1155 - acc: 0.3225 - val_loss: 1.9858 - val_acc: 0.5488
Epoch 2/50
42000/42000 [==============================] - 25s 603us/step - loss: 1.9177 - acc: 0.4118 - val_loss: 1.7973 - val_acc: 0.5658
Epoch 3/50
42000/42000 [==============================] - 27s 635us/step - loss: 1.7706 - acc: 0.4251 - val_loss: 1.6522 - val_acc: 0.5631
Epoch 4/50
42000/42000 [==============================] - 25s 604us/step - loss: 1.6597 - acc: 0.4352 - val_loss: 1.5234 - val_acc: 0.5848
Epoch 5/50
42000/42000 [==============================] - 25s 596us/step - loss: 1.5793 - acc: 0.4368 - val_loss: 1.4214 - val_acc: 0.5834
...
Epoch 45/50
42000/42000 [==============================] - 25s 606us/step - loss: 0.8357 - acc: 0.6731 - val_loss: 0.3728 - val_acc: 0.9060
Epoch 46/50
42000/42000 [==============================] - 25s 605us/step - loss: 0.8238 - acc: 0.6767 - val_loss: 0.3642 - val_acc: 0.9077
Epoch 47/50
42000/42000 [==============================] - 25s 602us/step - loss: 0.8121 - acc: 0.6809 - val_loss: 0.3694 - val_acc: 0.9034
Epoch 48/50
42000/42000 [==============================] - 25s 604us/step - loss: 0.8178 - acc: 0.6777 - val_loss: 0.3650 - val_acc: 0.9075
Epoch 49/50
42000/42000 [==============================] - 25s 604us/step - loss: 0.8037 - acc: 0.6900 - val_loss: 0.3715 - val_acc: 0.9079
Epoch 50/50
42000/42000 [==============================] - 25s 605us/step - loss: 0.7890 - acc: 0.6948 - val_loss: 0.3574 - val_acc: 0.9093

Test loss: 0.3465882527828217
Test accuracy: 0.9125
             precision    recall  f1-score   support

    Class 0       0.86      0.85      0.86      1000
    Class 1       0.99      0.98      0.99      1000
    Class 2       0.91      0.81      0.86      1000
    Class 3       0.91      0.94      0.92      1000
    Class 4       0.84      0.90      0.87      1000
    Class 5       0.99      0.98      0.99      1000
    Class 6       0.72      0.75      0.74      1000
    Class 7       0.95      0.97      0.96      1000
    Class 8       0.99      0.98      0.98      1000
    Class 9       0.97      0.97      0.97      1000

avg / total       0.91      0.91      0.91     10000

